{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGwXrDX9hbcG"
   },
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jjrp-gsPSG7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "import mne\n",
    "mne.set_log_level('error')\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "pd.options.display.max_columns = None # показываем все колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epochs_to_numpy(file_path):\n",
    "    shutil.unpack_archive(file_path, extract_dir=os.path.dirname(file_path), format=\"zip\")\n",
    "    fif_path = os.path.splitext(file_path)[0] + \".fif\"\n",
    "    epochs = mne.read_epochs(fif_path, preload=True)\n",
    "    os.remove(fif_path)\n",
    "\n",
    "    # --- Визуализация событий ---\n",
    "    fig, ax = plt.subplots(figsize=[15, 5])\n",
    "    mne.viz.plot_events(\n",
    "        epochs.events,\n",
    "        epochs.info[\"sfreq\"],\n",
    "        event_id=epochs.event_id,\n",
    "        axes=ax\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # --- Формирование X, y ---\n",
    "    X = epochs.get_data(copy=False)        # (epochs, channels, time)\n",
    "    y = epochs.events[:, 2]                # метки классов\n",
    "\n",
    "    shape = X.shape\n",
    "    n_epochs, n_channels, n_times = shape\n",
    "    X = X.reshape(n_epochs, n_channels * n_times)\n",
    "\n",
    "    print(f\"X исходная: {shape} (эпохи, каналы, время)\")\n",
    "    print(f\"X после reshape: {X.shape} (эпохи, признаки)\")\n",
    "    print(f\"y: {y.shape} (метки классов)\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=7,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_transfer(X_train, y_train, X_test, y_test, label):\n",
    "    # пересоздаем пайплайн при каждом запуске\n",
    "    xgb_classifier = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.2,\n",
    "        max_depth=7,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', xgb_classifier)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, pos_label=1),\n",
    "        'recall': recall_score(y_test, y_pred, pos_label=1),\n",
    "        'f1': f1_score(y_test, y_pred, pos_label=1)\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([metrics], index=[label]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'epochs\\sam40_full_epochs.zip'\n",
    "sam40_X, sam40_y = load_epochs_to_numpy(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'epochs\\distinguishing_epochs.zip'\n",
    "distinguishing_X, distinguishing_y = load_epochs_to_numpy(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_path = r'epochs\\sam40_stroop_epochs.zip'\n",
    "stroop_X, stroop_y = load_epochs_to_numpy(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'epochs\\sam40_arithmetic_epochs.zip'\n",
    "arithmetic_X, arithmetic_y = load_epochs_to_numpy(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'epochs\\sam40_mirror_epochs.zip'\n",
    "mirror_X, mirror_y = load_epochs_to_numpy(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cross-task внутри SAM40 --- #\n",
    "res1 = run_transfer(stroop_X, stroop_y,\n",
    "                    arithmetic_X, arithmetic_y,\n",
    "                    \"Stroop → Arithmetic\")\n",
    "\n",
    "res2 = run_transfer(stroop_X, stroop_y,\n",
    "                    mirror_X, mirror_y,\n",
    "                    \"Stroop → Mirror\")\n",
    "\n",
    "res3 = run_transfer(arithmetic_X, arithmetic_y,\n",
    "                    stroop_X, stroop_y,\n",
    "                    \"Arithmetic → Stroop\")\n",
    "\n",
    "res4 = run_transfer(arithmetic_X, arithmetic_y,\n",
    "                    mirror_X, mirror_y,\n",
    "                    \"Arithmetic → Mirror\")\n",
    "\n",
    "res5 = run_transfer(mirror_X, mirror_y,\n",
    "                    stroop_X, stroop_y,\n",
    "                    \"Mirror → Stroop\")\n",
    "\n",
    "res6 = run_transfer(mirror_X, mirror_y,\n",
    "                    arithmetic_X, arithmetic_y,\n",
    "                    \"Mirror → Arithmetic\")\n",
    "\n",
    "\n",
    "# --- Cross-dataset: SAM40 ↔ Distinguishing --- #\n",
    "res7 = run_transfer(distinguishing_X, distinguishing_y,\n",
    "                    sam40_X, sam40_y,\n",
    "                    \"Distinguishing → SAM40\")\n",
    "\n",
    "res8 = run_transfer(sam40_X, sam40_y,\n",
    "                    distinguishing_X, distinguishing_y,\n",
    "                    \"SAM40 → Distinguishing\")\n",
    "\n",
    "\n",
    "# --- Cross-dataset: Distinguishing → SAM40 subtasks --- #\n",
    "res9 = run_transfer(distinguishing_X, distinguishing_y,\n",
    "                    stroop_X, stroop_y,\n",
    "                    \"Distinguishing → Stroop\")\n",
    "\n",
    "res10 = run_transfer(distinguishing_X, distinguishing_y,\n",
    "                     arithmetic_X, arithmetic_y,\n",
    "                     \"Distinguishing → Arithmetic\")\n",
    "\n",
    "res11 = run_transfer(distinguishing_X, distinguishing_y,\n",
    "                     mirror_X, mirror_y,\n",
    "                     \"Distinguishing → Mirror\")\n",
    "\n",
    "\n",
    "# --- Cross-dataset: SAM40 subtasks → Distinguishing --- #\n",
    "res12 = run_transfer(stroop_X, stroop_y,\n",
    "                     distinguishing_X, distinguishing_y,\n",
    "                     \"Stroop → Distinguishing\")\n",
    "\n",
    "res13 = run_transfer(arithmetic_X, arithmetic_y,\n",
    "                     distinguishing_X, distinguishing_y,\n",
    "                     \"Arithmetic → Distinguishing\")\n",
    "\n",
    "res14 = run_transfer(mirror_X, mirror_y,\n",
    "                     distinguishing_X, distinguishing_y,\n",
    "                     \"Mirror → Distinguishing\")\n",
    "\n",
    "\n",
    "# --- Итоговая таблица --- #\n",
    "metrics_table = pd.concat([\n",
    "    res1, res2, res3, res4, res5, res6,   # cross-task\n",
    "    res7, res8,                           # full dataset → full dataset\n",
    "    res9, res10, res11,                   # Distinguishing → SAM40 subtasks\n",
    "    res12, res13, res14                   # SAM40 subtasks → Distinguishing\n",
    "])\n",
    "\n",
    "metrics_table"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
