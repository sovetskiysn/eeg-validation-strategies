{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zwcXIwyVgSG"
   },
   "source": [
    "# Distinguishing dataset\n",
    "\n",
    "\n",
    "\n",
    "**Dataset:** [EEG data for Mental Attention State Detection](\n",
    "https://www.kaggle.com/datasets/inancigdem/eeg-data-for-mental-attention-state-detection/data)\n",
    "\n",
    "**Article:** [Distinguishing mental attention states of humans via an EEG-based passive BCI using machine learning methods](https://sci-hub.ru/10.1016/j.eswa.2019.05.057)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGwXrDX9hbcG"
   },
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8jjrp-gsPSG7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "import mne\n",
    "mne.set_log_level('error')\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "pd.options.display.max_columns = None # показываем все колонки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinguishing epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinguishing_epochs = mne.read_epochs(r'epochs\\distinguishing_epochs.fif', preload=True)\n",
    "distinguishing_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=[15, 5])\n",
    "\n",
    "mne.viz.plot_events(\n",
    "    distinguishing_epochs.events,\n",
    "    distinguishing_epochs.info[\"sfreq\"],\n",
    "    event_id=distinguishing_epochs.event_id,\n",
    "    axes=ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = distinguishing_epochs.get_data(copy=False) \n",
    "y = distinguishing_epochs.events[:, 2]       \n",
    "\n",
    "shape = X.shape\n",
    "n_epochs, n_channels, n_times = X.shape\n",
    "X = X.reshape(n_epochs, n_channels * n_times)\n",
    "\n",
    "\n",
    "print(f\"X исходная: {shape} (эпохи, каналы, время)\")\n",
    "print(f\"X после reshape: {X.shape} (эпохи, признаки)\")\n",
    "print(f\"y: {y.shape} (метки классов)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_groups = distinguishing_epochs.metadata[\"session\"].values\n",
    "subject_groups = distinguishing_epochs.metadata[\"subject\"].values\n",
    "\n",
    "print(f\"subject_groups: {subject_groups.shape} \")\n",
    "print(f\"session_groups: {session_groups.shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,  cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  # Для бинарной классификации\n",
    "    n_estimators=100,             # Количество деревьев (можно увеличить)\n",
    "    learning_rate=0.2,            # Скорость обучения\n",
    "    max_depth=7,                  # Максимальная глубина дерева (можно настроить)\n",
    "    eval_metric='logloss',        # Метрика для бинарной классификации\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_classifier)\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "\n",
    "cv_results = cross_validate(pipeline, X, y, cv=skf, scoring=scoring)\n",
    "\n",
    "\n",
    "metrics_table = pd.DataFrame({\n",
    "    metric: cv_results[f'test_{metric}'] for metric in scoring.keys()\n",
    "})\n",
    "metrics_table.loc['mean'] = metrics_table.mean()\n",
    "metrics_table = metrics_table.round(2)\n",
    "\n",
    "\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# --- 3. Классификатор ---\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=7,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_classifier)\n",
    "])\n",
    "\n",
    "# --- 4. CV ---\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y,\n",
    "    cv=logo.split(X, y, groups=subject_groups),\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# --- 5. Результаты ---\n",
    "metrics_table = pd.DataFrame({\n",
    "    metric: cv_results[f'test_{metric}'] for metric in scoring.keys()\n",
    "})\n",
    "metrics_table.loc['mean'] = metrics_table.mean()\n",
    "metrics_table = metrics_table.round(2)\n",
    "\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# --- 3. Классификатор ---\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=7,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_classifier)\n",
    "])\n",
    "\n",
    "# --- 4. CV ---\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y,\n",
    "    cv=logo.split(X, y, groups=session_groups),\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# --- 5. Результаты ---\n",
    "metrics_table = pd.DataFrame({\n",
    "    metric: cv_results[f'test_{metric}'] for metric in scoring.keys()\n",
    "})\n",
    "metrics_table.loc['mean'] = metrics_table.mean()\n",
    "metrics_table = metrics_table.round(2)\n",
    "\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from xgboost import XGBClassifier\n",
    "# import numpy as np\n",
    "\n",
    "# # Параметры для бинарной классификации\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'objective': ['binary:logistic'],  # бинарная классификация\n",
    "#     'use_label_encoder': [False],     # чтобы избежать предупреждений\n",
    "#     'eval_metric': ['logloss']        # метрика для бинарной классификации\n",
    "# }\n",
    "\n",
    "# # Создаем GridSearchCV объект\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=XGBClassifier(random_state=42),\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',  # или другая подходящая метрика для бинарной классификации\n",
    "#     cv=3,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# print(\"Best parameters found by GridSearchCV:\")\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "# best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred_tuned_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "# print(\"\\nTuned XGBoost Model - Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred_tuned_xgb, target_names=['focused', 'unfocused']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters found by GridSearchCV:\n",
    "# {'eval_metric': 'logloss', 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300, 'objective': 'binary:logistic', 'use_label_encoder': False}\n",
    "\n",
    "# Tuned XGBoost Model - Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#      focused       0.86      0.87      0.86      8628\n",
    "#    unfocused       0.87      0.86      0.86      8640\n",
    "\n",
    "#     accuracy                           0.86     17268\n",
    "#    macro avg       0.86      0.86      0.86     17268\n",
    "# weighted avg       0.86      0.86      0.86     17268"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
